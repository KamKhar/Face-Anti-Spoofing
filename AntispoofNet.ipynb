{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torchvision \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def conv_block(in_f,out1,out2,out3):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv3d(in_channels=in_f, out_channels=out1, kernel_size=(1,3,3), stride=1,padding=(0,1,1)),\n",
    "        nn.BatchNorm3d(num_features=out1),\n",
    "        nn.ELU(),\n",
    "        nn.Conv3d(in_channels=out1, out_channels=out2, kernel_size=(1,3,3), stride=1,padding=(0,1,1)),\n",
    "        nn.BatchNorm3d(num_features=out2),\n",
    "        nn.ELU(),\n",
    "        nn.Conv3d(in_channels=out2, out_channels=out3, kernel_size=(1,3,3), stride=1,padding=(0,1,1)),\n",
    "        nn.BatchNorm3d(num_features=out3),\n",
    "        nn.ELU(),\n",
    "        nn.MaxPool3d(kernel_size=(1,2,2),stride=(1,2,2))\n",
    "    )\n",
    "    \n",
    "class CNN_part(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_part, self).__init__()\n",
    "\n",
    "        self.resize_64 = nn.Upsample(size=(5,32,32), mode='nearest')\n",
    "\n",
    "        # single layer (64)\n",
    "        self.con0 = nn.Conv3d(in_channels=3,out_channels=64,kernel_size=(1,3,3), stride=1,padding=(0,1,1))\n",
    "        self.bn0 = nn.BatchNorm3d(num_features=64)\n",
    "        self.act0 = nn.ELU()\n",
    "\n",
    "        #blocks\n",
    "\n",
    "        self.block1 = conv_block(64,128,196,128)\n",
    "        self.block2 = conv_block(128,128,196,128)\n",
    "        self.block3 = conv_block(128,128,196,128)\n",
    "\n",
    "        #Feature map\n",
    "        self.con1 = nn.Conv3d(in_channels=384, out_channels=128, kernel_size=(1,3,3), stride=1,padding=(0,1,1)) \n",
    "        self.con2 = nn.Conv3d(in_channels=128, out_channels=3, kernel_size=(1,3,3), stride=1,padding=(0,1,1))\n",
    "        self.con3 = nn.Conv3d(in_channels=3, out_channels=1, kernel_size=(1,3,3), stride=1,padding=(0,1,1))\n",
    "        #Depth map\n",
    "        self.con4 = nn.Conv3d(in_channels=384, out_channels=128, kernel_size=(1,3,3), stride=1,padding=(0,1,1)) \n",
    "        self.con5 = nn.Conv3d(in_channels=128, out_channels=64, kernel_size=(1,3,3), stride=1,padding=(0,1,1))\n",
    "        self.con6 = nn.Conv3d(in_channels=64, out_channels=1, kernel_size=(1,3,3), stride=1,padding=(0,1,1))\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        x1 = self.con0(x)\n",
    "        x2 = self.bn0(x1)\n",
    "        x3 = self.act0(x2)\n",
    "\n",
    "        x4 = self.block1(x3)\n",
    "        X1 = self.resize_64(x4)\n",
    "        x5 = self.block2(x4)\n",
    "        X2 = self.resize_64(x5)\n",
    "        print(X2.shape)\n",
    "        \n",
    "        x6 = self.block3(x5)\n",
    "        X3 = self.resize_64(x6)\n",
    "\n",
    "        inp = torch.cat((X1, X2, X3), 1)\n",
    "        \n",
    "        F1 = self.con1(inp)\n",
    "        F2 = self.con2(F1)\n",
    "        F3 = self.con3(F2)\n",
    "        \n",
    "        D1 = self.con4(inp)\n",
    "        D2 = self.con5(D1)\n",
    "        D3 = self.con6(D2)\n",
    "        \n",
    "        return D3, F3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class RNN_part(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN_part, self).__init__()\n",
    "\n",
    "        self.hidden = (torch.zeros(1, 1, 100).to(torch.device(\"cuda\")),torch.zeros(1, 1, 100).to(torch.device(\"cuda\")))\n",
    "        self.LSTM = nn.LSTM(input_size=32*32, hidden_size=100, num_layers=1,batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=500,out_features=100)\n",
    "\n",
    "    def forward(self, F):\n",
    "        F = F.view(1, 5, -1)\n",
    "        out, self.hidden = self.LSTM(F, self.hidden)\n",
    "        out = out.view(-1)\n",
    "        R = self.fc(out)\n",
    "        R = torch.rfft(R, signal_ndim=1, normalized=False)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Anti_spoof_net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Anti_spoof_net, self).__init__()\n",
    "\n",
    "        self.threshold = 0.1\n",
    "        self.CNN = CNN_part()\n",
    "        self.RNN = RNN_part()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        D, T = self.CNN(x)\n",
    "        # Non_rigid_registration_layer\n",
    "        V = torch.where(D >= self.threshold, torch.ones(1, 1, 5, 32, 32).to(torch.device(\"cuda\")), torch.zeros(1, 1, 5, 32, 32).to(torch.device(\"cuda\")))\n",
    "        U = T * V\n",
    "\n",
    "        #F = turning(U, anchors)\n",
    "        R = self.RNN(U)\n",
    "\n",
    "        return D, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "#torch.load(\"/kaggle/input/modell11/model\")\n",
    "#Anti_spoof_net().to(device)\n",
    "model =torch.load(\"/kaggle/input/modell11/model\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=3e-3,betas=(0.9, 0.999),eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def CNN_part_train(our_net,device, optimizer, load_train, anchor_train, criterion, N = 1):\n",
    "    total = 0\n",
    "    for epoch in range(N):\n",
    "        running_loss = 0.0\n",
    "        for i, (img,d,r) in enumerate(load_train, 0):\n",
    "            images, depth,_ = img.to(device),d.to(device),r.to(device)\n",
    "            if i >= 780:\n",
    "                # training step\n",
    "                optimizer.zero_grad()\n",
    "                net_depth, _ = our_net(images[:,:,0:1,:,:])\n",
    "                #handle NaN:\n",
    "                if (torch.norm((net_depth != net_depth).float())==0):  \n",
    "                    if i == 704:\n",
    "                        torch.save(our_net,'model') \n",
    "                    loss = criterion(depth[:,:,0:1,:,:], net_depth)\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    optimizer.step()\n",
    "                    # compute statistics\n",
    "                    print(depth.size(0))\n",
    "                    total += depth.size(0)\n",
    "                    running_loss += loss.item()\n",
    "                    print(labels_train[i])\n",
    "                    print(loss.item())\n",
    "                    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / total))\n",
    "\n",
    "        print('Epoch finished')\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_RNN(our_net,device, optimizer, load_train, anchor_train, criterion, N = 1):\n",
    "    total = 0\n",
    "    for epoch in range(N):\n",
    "        running_loss = 0.0\n",
    "        for i, (img,d,r) in enumerate(load_train, 0):\n",
    "            images, depth,rppg = img.to(device),d.to(device),r.to(device)\n",
    "            if i >= 0:\n",
    "                # training step\n",
    "                optimizer.zero_grad()\n",
    "                _, F = our_net(images)\n",
    "                #handle NaN:\n",
    "                if (torch.norm((F != F).float())==0):\n",
    "                    if i == 13:\n",
    "                        torch.save(our_net,'model')\n",
    "                    loss = criterion(F[:-1,0], rppg[0,:])\n",
    "                    loss.backward(retain_graph=True)\n",
    "                    optimizer.step()\n",
    "                    # compute statistics\n",
    "                    print(labels_train[i])\n",
    "                    print(loss.item())\n",
    "                    \n",
    "                    \n",
    "                    total += depth.size(0)\n",
    "                    running_loss += loss.item()\n",
    "                    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / total))\n",
    "        print('Epoch finished')\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_All(net,device, optimizer, load_train, anchor_train, criterion, N = 10):\n",
    "    for i in range(N):\n",
    "        CNN_part_train(net,device, optimizer, load_train, anchor_train, criterion)\n",
    "        torch.save(net,'mmodel')\n",
    "        train_RNN(net,device, optimizer, load_train, anchor_train, criterion)\n",
    "        torch.save(net,'modelll')\n",
    "        while(True):\n",
    "            print(\"lj\")\n",
    "    \n",
    "outputs = train_All(model,device, optimizer, load_train,anchor_train, criterion)\n",
    "\n",
    "model = torch.load('model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
